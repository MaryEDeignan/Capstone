<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="color-scheme" content="light dark">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.min.css">
    <style>
        body {
            margin: 10px 15px; /* Margins around the body */
            padding: 10px; 
            overflow-x: hidden;
        }
        
        /* Optional: Add padding to the content for better spacing */
        .content {
            padding: 20px; /* Optional padding for content */
        }
    </style>
    
    <title>Capstones</title>
</head>

<body>
    <div class="content">
        <h2 id="part 1">Part 1 (HW 3)</h2>
        <p>Create your own PyTorch class that implements the method of SCAD regularization and variable selection (smoothly clipped absolute deviations) for linear models. Your development should be based on the following references: 
            <ul>
                <li>https://andrewcharlesjones.github.io/journal/scad.html</li>
                <li>https://www.jstor.org/stable/27640214?seq=1 </li>
            </ul>
        <p>Test your method on a real data set and determine a variable selection based on features' importance, according to SCAD.</p>

        <h3 id="intro">Introduction</h3>
        <p>Smoothly Clipped Absolute Deviation (SCAD) is a regularization technique that can be used for variable selection in linear models. It applies a penalty that “smoothly” transitions from penalizing small coefficients linearly to imposing no penalty on larger coefficients. This process helps more accurately estimate the important predictors compared to traditional methods like Lasso. It also ensures that the model captures the effects of significant variables leading to better predictions and interpretations. SCAD encourages sparsity (when many of a model's coefficients are zero) which simplifies interpretation while maintaining high accuracy of estimations. My objective for this assignment was to implement SCAD regularization within the SCADLinearRegression class I created, train the model on the housing dataset, and evaluate its performance in selecting important features based on their significance.</p>

        <h3 id="process">Process</h3>
        <p>The SCADLinearRegression PyTorch class was created using Andy Jones SCAD penalty and derivative functions. To evaluate the performance of the SCAD implementation, the model was trained on the housing dataset, which contains various features related to housing prices in Massachusetts. First, the data was preprocessed by removing the categorical features and scaling the continuous features. The data was then split into training and test sets. Stochastic gradient descent (SGD) was used for optimization. During training, the model computes the total loss, which combines the Mean Squared Error with the SCAD penalty ensuring that the model not only fits the training data but also maintains a focus on feature selection. After training the model, it was possible to get the coefficients to determine which features were deemed significant based on their values.</p>
        
        <h3 id="findings">Findings</h3>
        <p>The coefficients found: </p>
            <ul>
            <li>crime: -0.816</li>
            <li>residential: 0.657</li>
            <li>industrial: -0.668</li>
            <li>nox: -0.768</li>
            <li>rooms: 2.751    </li>
            <li>older: -0.236</li>
            <li>distance: -2.337    </li>
            <li>tax: -0.316    </li>
            <li>ptratio: -1.538</li>
            <li>lstat: -3.715</li>
            </ul>
        <p>The positive coefficients indicate that an increase in the feature corresponds to an increase in predicted median home value (ex. as rooms increases, so does predicted median home value).</p>
        <p>The negative coefficients indicate than an increase in the feature corresponds to a decrease in predicted median home value (ex. as distance increases, predicted median home value decreases).</p>
        <p>Based on these coefficients, we can determine that rooms, ptratio, and lstat are all very significant variables in predicting median home value and should therefore stay in our model. None of the variables have zero-coefficients, meaning they are all contributing something to the model, so all of the features should likely stay; however, the features older and tax are contributing the least to the model. </p>



        
            
        <h4 id="Code">Code, Classes, and Data for Part 1</h4>
        <p><a href="https://github.com/MaryEDeignan/Capstone/blob/main/HW3/Homework_3.ipynb">Jupyter Notebook with Implementation</a></p>
        <p><a href="https://github.com/MaryEDeignan/Capstone/blob/main/HW3/SCAD_Class.py">SCAD Class</a></p>
        <p><a href="https://github.com/dvasiliu/AAML/blob/main/Data%20Sets/housing.csv">Housing Data Set</a></p>






    </div>
</body>

</html>

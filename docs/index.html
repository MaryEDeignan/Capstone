<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="color-scheme" content="light dark">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.min.css">
    <style>
        body {
            margin: 10px 20px; /* Margins around the body */
            padding: 0; /* Reset any default padding */
        }
        
        /* Optional: Add padding to the content for better spacing */
        .content {
            padding: 20px; /* Optional padding for content */
        }
    </style>
    
    <title>Capstones</title>
</head>

<body>
    <div class="content">
        <h1 id="capstone">Capstone Projects</h1>
        <h2 id="hw-1">Homework 1</h2>
        <p>Based on the examples provided, make your own class for implementing locally weighted regression to work with multiple features, and also train and test data. Show an application to a real data set with your implementation, and present the 10-fold cross-validated mean square error.</p>
        <p>Find my HW1 code <a href="https://github.com/MaryEDeignan/Capstone/blob/main/HW1/HW1.ipynb">here</a> and the data I used  <a href="https://github.com/MaryEDeignan/Capstone/blob/main/HW1/cars.csv">here!</a> <br></p>

        <h2 id="homework-2">Homework 2</h2>
        <h4 id="part-1">Part 1</h4>
        <p>Create your class that implements the Gradient Boosting concept, based on the locally weighted regression method (Lowess class), and that allows a user-prescribed number of boosting steps. The class you develop should have all the mainstream useful options, including “fit,” “is_fitted”, and “predict,” methods. Show applications with real data for regression, 10-fold cross-validations and compare the effect of different scalers, such as the “StandardScaler”, “MinMaxScaler”, and the “QuantileScaler”. In the case of the “Concrete” data set, determine a choice of hyperparameters that yield lower MSEs for your method when compared to the eXtream Gradient Boosting library.</p>

        <h4 id="part-2">Part 2</h4>
        <p>Implement your own version of Locally Weighted Logistic Regression and compare its performance on the Iris data set with the version presented in this article: <a href="https://calvintchi.github.io/classical_machine_learning/2020/08/16/lwlr.html">https://calvintchi.github.io/classical_machine_learning/2020/08/16/lwlr.html</a>.</p>
        <p><em>Present your results with detailed explanations and visualizations of the results in the format of a data science paper on Github.</em></p>
        <p>The link to my website with this Homework is <a href="https://maryedeignan.github.io/Homework2/">here!</a></p>
    </div>
</body>

</html>
